{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data cleansing\n",
    " - Part of Speech Tagging\n",
    " - Tokenization\n",
    " - Stemming & Lemmatization\n",
    " - Phrase Chunking\n",
    " - Keyword Extraction\n",
    " - Word Parsing\n",
    "- [Information Extraction](#info)\n",
    " - Entity Extraction\n",
    " - Relationship Building\n",
    " - Topic Extraction\n",
    "     - [Latent Dirichlet Allocation](#lda)\n",
    " \n",
    "syntactic, semantic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging probabilistically annotates each word with it's grammatical function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SDV](https://en.wikipedia.org/wiki/Singular_value_decomposition Singular value decomposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Named-entity extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[src nltk](http://www.nltk.org/book/ch07.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithms:\n",
    "CRF (supervised):\n",
    "- [Stanford NER](http://nlp.stanford.edu/software/CRF-NER.shtml) directly implemented in [NLTK](http://nlp.stanford.edu/software/CRF-NER.shtml) and [scrapy middleware](https://github.com/vu3jej/scrapy-corenlp)\n",
    "- [MIT](https://github.com/mit-nlp/MITIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RNN (unsupervised):\n",
    "- test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='info'></a>\n",
    "[back to top](#top)\n",
    "# Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation <a id='lda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet allocation is a way of automatically (probabistically) discovering topics that these documents in a set of documents contain.\n",
    "Example:\n",
    "Sentences 1 and 2: 100% Topic A\n",
    "Sentences 3 and 4: 100% Topic B\n",
    "Sentence 5: 60% Topic A, 40% Topic B\n",
    "Topic A: 30% broccoli, 15% bananas, 10% breakfast, 10% munching, ... (at which point, you could interpret topic A to be about food)\n",
    "Topic B: 20% chinchillas, 20% kittens, 20% cute, 15% hamster, ... (at which point, you could interpret topic B to be about cute animals)\n",
    "\n",
    "Assumption on how documents are created:\n",
    "1. Decide on number of words N in document\n",
    "2. Choose mixture of topics (50% topic A, 50% topic B)\n",
    "3. Generate each word in the document:\n",
    "    - Pick a topic from 2\n",
    "    - Pick a word (probabilistically) from words in topic A\n",
    "\n",
    "Learning:\n",
    "While learning, the model starts with a random assignment of topics to words and then tries optimizing based on prior probability of word in topic and word in document\n",
    "[src](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Model based recursive partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA can be refined by mixing it with a parametric model (e.g. tree model)\n",
    "-> Start with base learner (model tree)\n",
    "-> Refine with generative probabilistic model (LDA)\n",
    "[src](http://projecteuclid.org/download/pdfview_1/euclid.aoas/1372338461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
